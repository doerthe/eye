{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "observation_prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/josd/eye/blob/master/transduction/observation_prediction.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "dhe7TwGQgoio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transduction from observation to prediction"
      ]
    },
    {
      "metadata": {
        "id": "p24oSjZHgoiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "What is [Transduction (machine learning)](https://en.wikipedia.org/wiki/Transduction_(machine_learning%29):\n",
        "\n",
        "> In logic, statistical inference, and supervised learning, transduction or transductive inference is reasoning from observed, specific (training) cases to specific (test) cases. In contrast, induction is reasoning from observed training cases to general rules, which are then applied to the test cases. The distinction is most interesting in cases where the predictions of the transductive model are not achievable by any inductive model. Note that this is caused by transductive inference on different test sets producing mutually inconsistent predictions.\n",
        "\n",
        "What is the Tensor2Tensor [Transformer model](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py):\n",
        "\n",
        "> The Transformer model consists of an encoder and a decoder. Both are stacks\n",
        "of self-attention layers followed by feed-forward layers. This model yields\n",
        "good results on a number of problems, especially in NLP and machine translation.\n",
        "See \"Attention Is All You Need\" (https://arxiv.org/abs/1706.03762) for the full\n",
        "description of the model and the results obtained with its early version.\n",
        "\n",
        "![Transformer model](https://pbs.twimg.com/media/DCKhefrUMAE9stK.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "v5WnpUpkg7dO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "outputId": "92ac461b-0161-4d77-ac35-db8f50fadabf"
      },
      "cell_type": "code",
      "source": [
        "# Preparation\n",
        "\n",
        "! pip install -U tensor2tensor\n",
        "! curl -o observation_prediction.sh http://josd.github.io/eye/transduction/observation_prediction.sh\n",
        "! curl -o observation_prediction.py http://josd.github.io/eye/transduction/observation_prediction.py\n",
        "! curl -o __init__.py http://josd.github.io/eye/transduction/__init__.py\n",
        "! curl -o sample.observation http://josd.github.io/eye/transduction/sample.observation\n",
        "! chmod +x observation_prediction.sh\n",
        "#% rm -fr ~/t2t_train/observation_prediction/transformer-transformer_small/\n",
        "#% rm -fr ~/t2t_data/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://legacy.pypi.org/simple\n",
            "Requirement already up-to-date: tensor2tensor in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement not upgraded as not directly required: gevent in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (1.2.2)\n",
            "Requirement not upgraded as not directly required: future in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (0.16.0)\n",
            "Requirement not upgraded as not directly required: google-api-python-client in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (1.6.6)\n",
            "Requirement not upgraded as not directly required: numpy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (1.14.2)\n",
            "Requirement not upgraded as not directly required: bz2file in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (0.98)\n",
            "Requirement not upgraded as not directly required: scipy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (0.19.1)\n",
            "Requirement not upgraded as not directly required: sympy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (1.1.1)\n",
            "Requirement not upgraded as not directly required: gunicorn in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (19.7.1)\n",
            "Requirement not upgraded as not directly required: gym<=0.9.5 in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (0.9.5)\n",
            "Requirement not upgraded as not directly required: six in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (1.11.0)\n",
            "Requirement not upgraded as not directly required: flask in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (1.0)\n",
            "Requirement not upgraded as not directly required: requests in /usr/local/lib/python3.6/dist-packages (from tensor2tensor) (2.18.4)\n",
            "Requirement not upgraded as not directly required: greenlet>=0.4.10 in /usr/local/lib/python3.6/dist-packages (from gevent->tensor2tensor) (0.4.13)\n",
            "Requirement not upgraded as not directly required: oauth2client<5.0.0dev,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor) (4.1.2)\n",
            "Requirement not upgraded as not directly required: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor) (3.0.0)\n",
            "Requirement not upgraded as not directly required: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor) (0.11.3)\n",
            "Requirement not upgraded as not directly required: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->tensor2tensor) (1.0.0)\n",
            "Requirement not upgraded as not directly required: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<=0.9.5->tensor2tensor) (1.3.2)\n",
            "Requirement not upgraded as not directly required: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor) (2.10)\n",
            "Requirement not upgraded as not directly required: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor) (0.14.1)\n",
            "Requirement not upgraded as not directly required: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor) (0.24)\n",
            "Requirement not upgraded as not directly required: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor) (6.7)\n",
            "Requirement not upgraded as not directly required: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor) (2.6)\n",
            "Requirement not upgraded as not directly required: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor) (2018.4.16)\n",
            "Requirement not upgraded as not directly required: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor) (1.22)\n",
            "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor) (3.0.4)\n",
            "Requirement not upgraded as not directly required: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client->tensor2tensor) (0.2.1)\n",
            "Requirement not upgraded as not directly required: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client->tensor2tensor) (3.4.2)\n",
            "Requirement not upgraded as not directly required: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client->tensor2tensor) (0.4.2)\n",
            "Requirement not upgraded as not directly required: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask->tensor2tensor) (1.0)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1029  100  1029    0     0   1029      0  0:00:01 --:--:--  0:00:01 39576\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2118  100  2118    0     0   2118      0  0:00:01 --:--:--  0:00:01 84720\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    37  100    37    0     0     37      0  0:00:01 --:--:--  0:00:01  1541\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   109  100   109    0     0    109      0  0:00:01 --:--:--  0:00:01  2319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RYpFkp0uykNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1215
        },
        "outputId": "d3250b28-9f4a-490e-dc12-d3effe29fcf2"
      },
      "cell_type": "code",
      "source": [
        "# See the observation_prediction problem\n",
        "\n",
        "! pygmentize -g observation_prediction.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensor2tensor.data_generators\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m problem\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensor2tensor.data_generators\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m text_problems\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensor2tensor.utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m registry\r\n",
            "\r\n",
            "\u001b[30;01m@registry.register_problem\u001b[39;49;00m\r\n",
            "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mObservationPrediction\u001b[39;49;00m(text_problems.Text2TextProblem):\r\n",
            "  \u001b[33m\"\"\"Transduction from observation to prediction.\"\"\"\u001b[39;49;00m\r\n",
            "\r\n",
            "  \u001b[30;01m@property\u001b[39;49;00m\r\n",
            "  \u001b[34mdef\u001b[39;49;00m \u001b[32mapprox_vocab_size\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
            "    \u001b[34mreturn\u001b[39;49;00m \u001b[34m2\u001b[39;49;00m**\u001b[34m14\u001b[39;49;00m  \u001b[37m# ~16k\u001b[39;49;00m\r\n",
            "\r\n",
            "  \u001b[30;01m@property\u001b[39;49;00m\r\n",
            "  \u001b[34mdef\u001b[39;49;00m \u001b[32mis_generate_per_split\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
            "    \u001b[37m# generate_data will shard the data into TRAIN and EVAL for us.\u001b[39;49;00m\r\n",
            "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mFalse\u001b[39;49;00m\r\n",
            "\r\n",
            "  \u001b[30;01m@property\u001b[39;49;00m\r\n",
            "  \u001b[34mdef\u001b[39;49;00m \u001b[32mdataset_splits\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
            "    \u001b[33m\"\"\"Splits of data to produce and number of output shards for each.\"\"\"\u001b[39;49;00m\r\n",
            "    \u001b[37m# 50% evaluation data\u001b[39;49;00m\r\n",
            "    \u001b[34mreturn\u001b[39;49;00m [{\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33msplit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: problem.DatasetSplit.TRAIN,\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33mshards\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m5\u001b[39;49;00m,\r\n",
            "    }, {\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33msplit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: problem.DatasetSplit.EVAL,\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33mshards\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m5\u001b[39;49;00m,\r\n",
            "    }]\r\n",
            "\r\n",
            "  \u001b[34mdef\u001b[39;49;00m \u001b[32mgenerate_samples\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, data_dir, tmp_dir, dataset_split):\r\n",
            "    \u001b[34mdel\u001b[39;49;00m data_dir\r\n",
            "    \u001b[34mdel\u001b[39;49;00m tmp_dir\r\n",
            "    \u001b[34mdel\u001b[39;49;00m dataset_split\r\n",
            "\r\n",
            "    \u001b[34mfor\u001b[39;49;00m n \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m10000\u001b[39;49;00m):\r\n",
            "      \u001b[37m# wind turbine size factor\u001b[39;49;00m\r\n",
            "      size_factor = random.randint(\u001b[34m1\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\r\n",
            "      \u001b[37m# wind speed\u001b[39;49;00m\r\n",
            "      wind_speed = \u001b[36mmax\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(random.gauss(\u001b[34m25\u001b[39;49;00m, \u001b[34m15\u001b[39;49;00m)))\r\n",
            "      \u001b[37m# wind turbine power\u001b[39;49;00m\r\n",
            "      turbine_power = \u001b[36mint\u001b[39;49;00m(\u001b[34m0.01\u001b[39;49;00m*size_factor*wind_speed**\u001b[34m3\u001b[39;49;00m)\r\n",
            "      \u001b[34myield\u001b[39;49;00m {\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_TURBINE with size factor \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(size_factor) + \u001b[33m\"\u001b[39;49;00m\u001b[33m and subjected to windspeed \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(wind_speed) + \u001b[33m\"\u001b[39;49;00m\u001b[33m km/h\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33mtargets\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_TURBINE producing \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(turbine_power) + \u001b[33m\"\u001b[39;49;00m\u001b[33m kW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
            "      }\r\n",
            "\r\n",
            "      \u001b[37m# weight\u001b[39;49;00m\r\n",
            "      weight = \u001b[36mmax\u001b[39;49;00m(\u001b[34m35\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(random.gauss(\u001b[34m62\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m)))\r\n",
            "      \u001b[37m# height\u001b[39;49;00m\r\n",
            "      height = \u001b[36mmax\u001b[39;49;00m(\u001b[34m110\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(random.gauss(\u001b[34m170\u001b[39;49;00m, \u001b[34m15\u001b[39;49;00m)))\r\n",
            "      \u001b[37m# body mass index\u001b[39;49;00m\r\n",
            "      bmi = \u001b[36mint\u001b[39;49;00m(weight/(height*\u001b[34m0.01\u001b[39;49;00m)**\u001b[34m2\u001b[39;49;00m)\r\n",
            "      \u001b[34mif\u001b[39;49;00m bmi < \u001b[34m18\u001b[39;49;00m:\r\n",
            "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mU\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
            "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m18\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m25\u001b[39;49;00m:\r\n",
            "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
            "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m25\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m30\u001b[39;49;00m:\r\n",
            "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
            "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m30\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m35\u001b[39;49;00m:\r\n",
            "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
            "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m35\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m40\u001b[39;49;00m:\r\n",
            "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
            "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m40\u001b[39;49;00m:\r\n",
            "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO3\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
            "      \u001b[34myield\u001b[39;49;00m {\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_PERSON with weight \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(weight) + \u001b[33m\"\u001b[39;49;00m\u001b[33m kg and height \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(height) + \u001b[33m\"\u001b[39;49;00m\u001b[33m cm\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
            "        \u001b[33m\"\u001b[39;49;00m\u001b[33mtargets\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_PERSON has BMI class \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + bmi_class\r\n",
            "      }\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5F7TRqbByL1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "80830e09-8672-4b62-add2-55675940e531"
      },
      "cell_type": "code",
      "source": [
        "# See the observation_prediction script\n",
        "\n",
        "! pygmentize -g observation_prediction.sh"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[37m#!/bin/bash\u001b[39;49;00m\r\n",
            "\u001b[31mPROBLEM\u001b[39;49;00m=observation_prediction\r\n",
            "\u001b[31mMODEL\u001b[39;49;00m=transformer\r\n",
            "\u001b[31mHPARAMS\u001b[39;49;00m=transformer_small\r\n",
            "\r\n",
            "\u001b[31mUSER_DIR\u001b[39;49;00m=\u001b[31m$PWD\u001b[39;49;00m\r\n",
            "\u001b[31mDATA_DIR\u001b[39;49;00m=\u001b[31m$HOME\u001b[39;49;00m/t2t_data\r\n",
            "\u001b[31mTMP_DIR\u001b[39;49;00m=/tmp/t2t_datagen\r\n",
            "\u001b[31mTRAIN_DIR\u001b[39;49;00m=\u001b[31m$HOME\u001b[39;49;00m/t2t_train/\u001b[31m$PROBLEM\u001b[39;49;00m/\u001b[31m$MODEL\u001b[39;49;00m-\u001b[31m$HPARAMS\u001b[39;49;00m\r\n",
            "\r\n",
            "mkdir -p \u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[31m$TMP_DIR\u001b[39;49;00m \u001b[31m$TRAIN_DIR\u001b[39;49;00m\r\n",
            "\r\n",
            "\u001b[37m# Generate data\u001b[39;49;00m\r\n",
            "t2t-datagen \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --data_dir=\u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --problem=\u001b[31m$PROBLEM\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --t2t_usr_dir=\u001b[31m$USER_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --tmp_dir=\u001b[31m$TMP_DIR\u001b[39;49;00m\r\n",
            "\r\n",
            "\u001b[37m# Train\u001b[39;49;00m\r\n",
            "t2t-trainer \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --data_dir=\u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --eval_steps=\u001b[34m3\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --hparams_set=\u001b[31m$HPARAMS\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --local_eval_frequency=\u001b[34m100\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --model=\u001b[31m$MODEL\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --output_dir=\u001b[31m$TRAIN_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --problem=\u001b[31m$PROBLEM\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --t2t_usr_dir=\u001b[31m$USER_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --train_steps=\u001b[34m2000\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --worker_gpu_memory_fraction=0.75\r\n",
            "\r\n",
            "\u001b[37m# Decode\u001b[39;49;00m\r\n",
            "t2t-decoder \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --data_dir=\u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --decode_from_file=sample.observation \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --decode_hparams=\u001b[33m\"beam_size=3,alpha=0.6,return_beams=True,write_beam_scores=True\"\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --decode_to_file=sample.prediction \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --hparams_set=\u001b[31m$HPARAMS\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --model=\u001b[31m$MODEL\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --output_dir=\u001b[31m$TRAIN_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --problem=\u001b[31m$PROBLEM\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --t2t_usr_dir=\u001b[31m$USER_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "  --worker_gpu_memory_fraction=0.75\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XqaxB8hqgoi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6376
        },
        "outputId": "12aef1a1-c787-4faf-c088-9bb719fb7bff"
      },
      "cell_type": "code",
      "source": [
        "# Run the observation_prediction script\n",
        "\n",
        "! ./observation_prediction.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
            "  from ._conv import register_converters as _register_converters\n",
            "INFO:tensorflow:Importing user module content from path /\n",
            "[2018-04-26 21:50:29,277] Importing user module content from path /\n",
            "INFO:tensorflow:Generating problems:\n",
            "    observation:\n",
            "      * observation_prediction\n",
            "[2018-04-26 21:50:29,279] Generating problems:\n",
            "    observation:\n",
            "      * observation_prediction\n",
            "INFO:tensorflow:Generating data for observation_prediction.\n",
            "[2018-04-26 21:50:29,280] Generating data for observation_prediction.\n",
            "INFO:tensorflow:Found vocab file: /content/t2t_data/vocab.observation_prediction.16384.subwords\n",
            "[2018-04-26 21:50:29,280] Found vocab file: /content/t2t_data/vocab.observation_prediction.16384.subwords\n",
            "INFO:tensorflow:Skipping generator because outputs files exist\n",
            "[2018-04-26 21:50:29,291] Skipping generator because outputs files exist\n",
            "INFO:tensorflow:Skipping shuffle because output files exist\n",
            "[2018-04-26 21:50:29,294] Skipping shuffle because output files exist\n",
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "INFO:tensorflow:Importing user module content from path /\n",
            "[2018-04-26 21:50:38,391] Importing user module content from path /\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "[2018-04-26 21:50:38,531] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "[2018-04-26 21:50:38,531] schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "[2018-04-26 21:50:38,531] worker_gpu=1\n",
            "INFO:tensorflow:sync=False\n",
            "[2018-04-26 21:50:38,532] sync=False\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "[2018-04-26 21:50:38,532] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "[2018-04-26 21:50:38,532] datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:caching_devices: None\n",
            "[2018-04-26 21:50:38,533] caching_devices: None\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "[2018-04-26 21:50:38,533] ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc767f2eeb8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': 1234, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.75\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "  }\n",
            "}\n",
            ", '_save_checkpoints_steps': 100, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/content/t2t_train/observation_prediction/transformer-transformer_small', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc76dabf908>}\n",
            "[2018-04-26 21:50:38,545] Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc767f2eeb8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': 1234, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.75\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "  }\n",
            "}\n",
            ", '_save_checkpoints_steps': 100, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/content/t2t_train/observation_prediction/transformer-transformer_small', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fc76dabf908>}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc767f1c620>) includes params argument, but params are not passed to Estimator.\n",
            "[2018-04-26 21:50:38,546] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fc767f1c620>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
            "[2018-04-26 21:50:38,546] ValidationMonitor only works with --schedule=train_and_evaluate\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:334: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
            "[2018-04-26 21:50:38,548] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:334: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
            "WARNING:tensorflow:Experiment.continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
            "[2018-04-26 21:50:38,550] Experiment.continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Training model for 100 steps\n",
            "[2018-04-26 21:50:38,550] Training model for 100 steps\n",
            "INFO:tensorflow:Reading data files from /content/t2t_data/observation_prediction-train*\n",
            "[2018-04-26 21:50:38,573] Reading data files from /content/t2t_data/observation_prediction-train*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 5\n",
            "[2018-04-26 21:50:38,574] partition: 0 num_data_files: 5\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "[2018-04-26 21:50:38,775] Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
            "[2018-04-26 21:50:42,252] Setting T2TModel mode to 'train'\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "[2018-04-26 21:50:42,253] Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_754_256.bottom\n",
            "[2018-04-26 21:50:42,298] Transforming feature 'inputs' with symbol_modality_754_256.bottom\n",
            "INFO:tensorflow:Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
            "[2018-04-26 21:50:42,514] Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            "[2018-04-26 21:50:42,523] Building model body\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "[2018-04-26 21:50:42,623] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_754_256.top\n",
            "[2018-04-26 21:50:44,988] Transforming body output with symbol_modality_754_256.top\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:1781: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n",
            "[2018-04-26 21:50:45,057] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:1781: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
            "\n",
            "INFO:tensorflow:Base learning rate: 0.200000\n",
            "[2018-04-26 21:50:45,097] Base learning rate: 0.200000\n",
            "INFO:tensorflow:Trainable Variables Total size: 3882496\n",
            "[2018-04-26 21:50:45,108] Trainable Variables Total size: 3882496\n",
            "INFO:tensorflow:Using optimizer Adam\n",
            "[2018-04-26 21:50:45,108] Using optimizer Adam\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\r\n",
            "[2018-04-26 21:50:48,950] Done calling model_fn.\r\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\r\n",
            "[2018-04-26 21:50:48,952] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "[2018-04-26 21:50:50,580] Graph was finalized.\n",
            "2018-04-26 21:50:50.673017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-04-26 21:50:50.673405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-04-26 21:50:50.673442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\n",
            "2018-04-26 21:50:51.007701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-04-26 21:50:51.007757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \n",
            "2018-04-26 21:50:51.007782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \n",
            "2018-04-26 21:50:51.008119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8579 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2000\n",
            "[2018-04-26 21:50:51,198] Restoring parameters from /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "[2018-04-26 21:50:51,946] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[2018-04-26 21:50:52,005] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2001 into /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
            "[2018-04-26 21:50:59,977] Saving checkpoints for 2001 into /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.026880924, step = 2000\n",
            "[2018-04-26 21:51:00,839] loss = 0.026880924, step = 2000\n",
            "INFO:tensorflow:Saving checkpoints for 2100 into /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
            "[2018-04-26 21:51:14,728] Saving checkpoints for 2100 into /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.032259025.\n",
            "[2018-04-26 21:51:15,667] Loss for final step: 0.032259025.\n",
            "INFO:tensorflow:Evaluating model now.\n",
            "[2018-04-26 21:51:15,668] Evaluating model now.\n",
            "INFO:tensorflow:Reading data files from /content/t2t_data/observation_prediction-dev*\n",
            "[2018-04-26 21:51:15,675] Reading data files from /content/t2t_data/observation_prediction-dev*\n",
            "INFO:tensorflow:partition: 0 num_data_files: 5\n",
            "[2018-04-26 21:51:15,676] partition: 0 num_data_files: 5\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "[2018-04-26 21:51:15,834] Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
            "[2018-04-26 21:51:19,278] Setting T2TModel mode to 'eval'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "[2018-04-26 21:51:19,279] Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "[2018-04-26 21:51:19,279] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "[2018-04-26 21:51:19,279] Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "[2018-04-26 21:51:19,279] Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "[2018-04-26 21:51:19,279] Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
            "[2018-04-26 21:51:19,280] Using variable initializer: uniform_unit_scaling\n",
            "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_754_256.bottom\n",
            "[2018-04-26 21:51:19,333] Transforming feature 'inputs' with symbol_modality_754_256.bottom\n",
            "INFO:tensorflow:Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
            "[2018-04-26 21:51:19,446] Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
            "INFO:tensorflow:Building model body\n",
            "[2018-04-26 21:51:19,456] Building model body\n",
            "INFO:tensorflow:Transforming body output with symbol_modality_754_256.top\n",
            "[2018-04-26 21:51:21,953] Transforming body output with symbol_modality_754_256.top\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "[2018-04-26 21:51:22,720] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-04-26-21:51:22\n",
            "[2018-04-26 21:51:22,741] Starting evaluation at 2018-04-26-21:51:22\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "[2018-04-26 21:51:22,969] Graph was finalized.\n",
            "2018-04-26 21:51:22.970183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\n",
            "2018-04-26 21:51:22.970266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-04-26 21:51:22.970294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \n",
            "2018-04-26 21:51:22.970317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \n",
            "2018-04-26 21:51:22.970544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8579 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2100\n",
            "[2018-04-26 21:51:22,970] Restoring parameters from /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "[2018-04-26 21:51:23,298] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[2018-04-26 21:51:23,342] Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/3]\n",
            "[2018-04-26 21:51:24,473] Evaluation [1/3]\n",
            "INFO:tensorflow:Evaluation [2/3]\n",
            "[2018-04-26 21:51:24,636] Evaluation [2/3]\n",
            "INFO:tensorflow:Evaluation [3/3]\n",
            "[2018-04-26 21:51:24,797] Evaluation [3/3]\n",
            "INFO:tensorflow:Finished evaluation at 2018-04-26-21:51:24\n",
            "[2018-04-26 21:51:24,989] Finished evaluation at 2018-04-26-21:51:24\n",
            "INFO:tensorflow:Saving dict for global step 2100: global_step = 2100, loss = 0.044566248, metrics-observation_prediction/accuracy = 0.99488395, metrics-observation_prediction/accuracy_per_sequence = 0.9687075, metrics-observation_prediction/accuracy_top5 = 0.99853826, metrics-observation_prediction/approx_bleu_score = 0.7532262, metrics-observation_prediction/neg_log_perplexity = -0.09438076, metrics-observation_prediction/rouge_2_fscore = 0.82683927, metrics-observation_prediction/rouge_L_fscore = 0.79812163\n",
            "[2018-04-26 21:51:24,989] Saving dict for global step 2100: global_step = 2100, loss = 0.044566248, metrics-observation_prediction/accuracy = 0.99488395, metrics-observation_prediction/accuracy_per_sequence = 0.9687075, metrics-observation_prediction/accuracy_top5 = 0.99853826, metrics-observation_prediction/approx_bleu_score = 0.7532262, metrics-observation_prediction/neg_log_perplexity = -0.09438076, metrics-observation_prediction/rouge_2_fscore = 0.82683927, metrics-observation_prediction/rouge_L_fscore = 0.79812163\n",
            "INFO:tensorflow:Stop training model as max steps reached\n",
            "[2018-04-26 21:51:25,725] Stop training model as max steps reached\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
            "  from ._conv import register_converters as _register_converters\n",
            "INFO:tensorflow:Importing user module content from path /\n",
            "[2018-04-26 21:51:35,821] Importing user module content from path /\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "[2018-04-26 21:51:35,981] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:schedule=continuous_train_and_eval\n",
            "[2018-04-26 21:51:35,981] schedule=continuous_train_and_eval\n",
            "INFO:tensorflow:worker_gpu=1\n",
            "[2018-04-26 21:51:35,981] worker_gpu=1\n",
            "INFO:tensorflow:sync=False\n",
            "[2018-04-26 21:51:35,982] sync=False\n",
            "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "[2018-04-26 21:51:35,982] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
            "[2018-04-26 21:51:35,983] datashard_devices: ['gpu:0']\n",
            "INFO:tensorflow:caching_devices: None\n",
            "[2018-04-26 21:51:35,983] caching_devices: None\n",
            "INFO:tensorflow:ps_devices: ['gpu:0']\n",
            "[2018-04-26 21:51:35,984] ps_devices: ['gpu:0']\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa8f6000668>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': 1234, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.75\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "  }\n",
            "}\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/content/t2t_train/observation_prediction/transformer-transformer_small', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fa905868320>}\n",
            "[2018-04-26 21:51:35,984] Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa8f6000668>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': 1234, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.75\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "  }\n",
            "}\n",
            ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/content/t2t_train/observation_prediction/transformer-transformer_small', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fa905868320>}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fa8fa9ef8c8>) includes params argument, but params are not passed to Estimator.\n",
            "[2018-04-26 21:51:35,984] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fa8fa9ef8c8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:decode_hp.batch_size not specified; default=32\n",
            "[2018-04-26 21:51:35,985] decode_hp.batch_size not specified; default=32\n",
            "INFO:tensorflow:Performing decoding from a file.\n",
            "[2018-04-26 21:51:35,985] Performing decoding from a file.\n",
            "INFO:tensorflow:Getting sorted inputs\n",
            "[2018-04-26 21:51:35,985] Getting sorted inputs\n",
            "INFO:tensorflow: batch 1\n",
            "[2018-04-26 21:51:36,000]  batch 1\n",
            "INFO:tensorflow:Decoding batch 0\n",
            "[2018-04-26 21:51:36,000] Decoding batch 0\n",
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "[2018-04-26 21:51:36,008] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "[2018-04-26 21:51:36,008] Calling model_fn.\n",
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
            "[2018-04-26 21:51:39,500] Setting T2TModel mode to 'infer'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "[2018-04-26 21:51:39,500] Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "[2018-04-26 21:51:39,500] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "[2018-04-26 21:51:39,500] Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "[2018-04-26 21:51:39,501] Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "[2018-04-26 21:51:39,501] Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:Beam Decoding with beam size 3\n",
            "[2018-04-26 21:51:39,501] Beam Decoding with beam size 3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "[2018-04-26 21:51:39,846] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/beam_search.py:93: calling reduce_logsumexp (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "[2018-04-26 21:51:42,283] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/beam_search.py:93: calling reduce_logsumexp (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "[2018-04-26 21:51:42,381] Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "[2018-04-26 21:51:42,589] Graph was finalized.\n",
            "2018-04-26 21:51:42.667843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-04-26 21:51:42.668260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-04-26 21:51:42.668315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\n",
            "2018-04-26 21:51:43.012291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-04-26 21:51:43.012355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \n",
            "2018-04-26 21:51:43.012384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \n",
            "2018-04-26 21:51:43.012702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8579 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2100\n",
            "[2018-04-26 21:51:43,206] Restoring parameters from /content/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "[2018-04-26 21:51:43,485] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[2018-04-26 21:51:43,499] Done running local_init_op.\n",
            "INFO:tensorflow:BEAM 0:\n",
            "[2018-04-26 21:51:45,880] BEAM 0:\n",
            "INFO:tensorflow:Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
            "[2018-04-26 21:51:45,880] Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
            "INFO:tensorflow:Inference results OUTPUT: A_TURBINE producing 9533 kW\n",
            "[2018-04-26 21:51:45,880] Inference results OUTPUT: A_TURBINE producing 9533 kW\n",
            "INFO:tensorflow:BEAM 1:\n",
            "[2018-04-26 21:51:45,881] BEAM 1:\n",
            "INFO:tensorflow:Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
            "[2018-04-26 21:51:45,881] Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
            "INFO:tensorflow:Inference results OUTPUT: A_TURBINE producing 16682 kW\n",
            "[2018-04-26 21:51:45,881] Inference results OUTPUT: A_TURBINE producing 16682 kW\n",
            "INFO:tensorflow:BEAM 2:\n",
            "[2018-04-26 21:51:45,882] BEAM 2:\n",
            "INFO:tensorflow:Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
            "[2018-04-26 21:51:45,882] Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
            "INFO:tensorflow:Inference results OUTPUT: A_TURBINE producing 16208 kW\n",
            "[2018-04-26 21:51:45,882] Inference results OUTPUT: A_TURBINE producing 16208 kW\n",
            "INFO:tensorflow:BEAM 0:\n",
            "[2018-04-26 21:51:45,883] BEAM 0:\n",
            "INFO:tensorflow:Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
            "[2018-04-26 21:51:45,883] Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
            "INFO:tensorflow:Inference results OUTPUT: A_PERSON has BMI class N\n",
            "[2018-04-26 21:51:45,884] Inference results OUTPUT: A_PERSON has BMI class N\n",
            "INFO:tensorflow:BEAM 1:\n",
            "[2018-04-26 21:51:45,884] BEAM 1:\n",
            "INFO:tensorflow:Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
            "[2018-04-26 21:51:45,884] Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
            "INFO:tensorflow:Inference results OUTPUT: A_PERSON has BMI class U\n",
            "[2018-04-26 21:51:45,884] Inference results OUTPUT: A_PERSON has BMI class U\n",
            "INFO:tensorflow:BEAM 2:\n",
            "[2018-04-26 21:51:45,885] BEAM 2:\n",
            "INFO:tensorflow:Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
            "[2018-04-26 21:51:45,885] Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
            "INFO:tensorflow:Inference results OUTPUT: A_PERSON has BMI class O\n",
            "[2018-04-26 21:51:45,885] Inference results OUTPUT: A_PERSON has BMI class O\n",
            "INFO:tensorflow:Writing decodes into sample.prediction\n",
            "[2018-04-26 21:51:45,888] Writing decodes into sample.prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ENGaCZllgojm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7db8af41-3a09-4cec-b662-dcd9e74245e4"
      },
      "cell_type": "code",
      "source": [
        "# See the transductions\n",
        "# For each target the top 3 is shown with their scores (log probability)\n",
        "\n",
        "! pygmentize -g sample.observation\n",
        "print(\"->-\")\n",
        "! pygmentize -g sample.prediction"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A_PERSON with weight 74 kg and height 179 cm\r\n",
            "A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\r\n",
            "->-\n",
            "A_PERSON has BMI class N\t-0.34\tA_PERSON has BMI class U\t-4.58\tA_PERSON has BMI class O\t-5.07\n",
            "A_TURBINE producing 9533 kW\t-0.36\tA_TURBINE producing 16682 kW\t-3.11\tA_TURBINE producing 16208 kW\t-5.05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}