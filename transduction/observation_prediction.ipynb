{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhe7TwGQgoio"
   },
   "source": [
    "# Transduction from observation to prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p24oSjZHgoiy"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Excerpt from Wikipedia [Transduction (machine learning)](https://en.wikipedia.org/wiki/Transduction_(machine_learning%29):\n",
    "\n",
    "In logic, statistical inference, and supervised learning, transduction or transductive inference is reasoning from observed, specific (training) cases to specific (test) cases. In contrast, induction is reasoning from observed training cases to general rules, which are then applied to the test cases. The distinction is most interesting in cases where the predictions of the transductive model are not achievable by any inductive model. Note that this is caused by transductive inference on different test sets producing mutually inconsistent predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12860,
     "status": "ok",
     "timestamp": 1524660985584,
     "user": {
      "displayName": "Jos De Roo",
      "photoUrl": "//lh4.googleusercontent.com/-k8HF8cH0nRA/AAAAAAAAAAI/AAAAAAAAY58/KtQscbCb1JA/s50-c-k-no/photo.jpg",
      "userId": "112414952198343096006"
     },
     "user_tz": -120
    },
    "id": "v5WnpUpkg7dO",
    "outputId": "81f281d7-3cc0-4ec2-e0b5-75b7b68bd040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensor2tensor in /usr/local/lib/python3.5/dist-packages (1.6.0)\n",
      "Requirement not upgraded as not directly required: future in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (0.16.0)\n",
      "Requirement not upgraded as not directly required: flask in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (0.12.2)\n",
      "Requirement not upgraded as not directly required: gevent in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (1.2.2)\n",
      "Requirement not upgraded as not directly required: google-api-python-client in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (1.6.6)\n",
      "Requirement not upgraded as not directly required: numpy in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (1.14.2)\n",
      "Requirement not upgraded as not directly required: requests in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (2.18.4)\n",
      "Requirement not upgraded as not directly required: gunicorn in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (19.7.1)\n",
      "Requirement not upgraded as not directly required: scipy in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (1.0.1)\n",
      "Requirement not upgraded as not directly required: sympy in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (1.1.1)\n",
      "Requirement not upgraded as not directly required: gym<=0.9.5 in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (0.9.5)\n",
      "Requirement not upgraded as not directly required: six in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (1.11.0)\n",
      "Requirement not upgraded as not directly required: bz2file in /usr/local/lib/python3.5/dist-packages (from tensor2tensor) (0.98)\n",
      "Requirement not upgraded as not directly required: itsdangerous>=0.21 in /usr/local/lib/python3.5/dist-packages (from flask->tensor2tensor) (0.24)\n",
      "Requirement not upgraded as not directly required: Werkzeug>=0.7 in /usr/local/lib/python3.5/dist-packages (from flask->tensor2tensor) (0.14.1)\n",
      "Requirement not upgraded as not directly required: click>=2.0 in /usr/local/lib/python3.5/dist-packages (from flask->tensor2tensor) (6.7)\n",
      "Requirement not upgraded as not directly required: Jinja2>=2.4 in /usr/local/lib/python3.5/dist-packages (from flask->tensor2tensor) (2.10)\n",
      "Requirement not upgraded as not directly required: greenlet>=0.4.10 in /usr/local/lib/python3.5/dist-packages (from gevent->tensor2tensor) (0.4.13)\n",
      "Requirement not upgraded as not directly required: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.5/dist-packages (from google-api-python-client->tensor2tensor) (0.11.3)\n",
      "Requirement not upgraded as not directly required: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from google-api-python-client->tensor2tensor) (3.0.0)\n",
      "Requirement not upgraded as not directly required: oauth2client<5.0.0dev,>=1.5.0 in /usr/local/lib/python3.5/dist-packages (from google-api-python-client->tensor2tensor) (4.1.2)\n",
      "Requirement not upgraded as not directly required: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests->tensor2tensor) (1.22)\n",
      "Requirement not upgraded as not directly required: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests->tensor2tensor) (2018.1.18)\n",
      "Requirement not upgraded as not directly required: idna<2.7,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests->tensor2tensor) (2.6)\n",
      "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests->tensor2tensor) (3.0.4)\n",
      "Requirement not upgraded as not directly required: mpmath>=0.19 in /usr/local/lib/python3.5/dist-packages (from sympy->tensor2tensor) (1.0.0)\n",
      "Requirement not upgraded as not directly required: pyglet>=1.2.0 in /usr/local/lib/python3.5/dist-packages (from gym<=0.9.5->tensor2tensor) (1.3.2)\n",
      "Requirement not upgraded as not directly required: MarkupSafe>=0.23 in /usr/local/lib/python3.5/dist-packages (from Jinja2>=2.4->flask->tensor2tensor) (1.0)\n",
      "Requirement not upgraded as not directly required: pyasn1>=0.1.7 in /usr/local/lib/python3.5/dist-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client->tensor2tensor) (0.4.2)\n",
      "Requirement not upgraded as not directly required: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.5/dist-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client->tensor2tensor) (0.2.1)\n",
      "Requirement not upgraded as not directly required: rsa>=3.1.4 in /usr/local/lib/python3.5/dist-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client->tensor2tensor) (3.4.2)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1029  100  1029    0     0   6457      0 --:--:-- --:--:-- --:--:--  6471\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2118  100  2118    0     0   4103      0 --:--:-- --:--:-- --:--:--  4096\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    37  100    37    0     0    257      0 --:--:-- --:--:-- --:--:--   258\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   109  100   109    0     0    739      0 --:--:-- --:--:-- --:--:--   741\n"
     ]
    }
   ],
   "source": [
    "# Preparation\n",
    "\n",
    "! pip install -U tensor2tensor\n",
    "! curl -o observation_prediction.sh http://josd.github.io/eye/transduction/observation_prediction.sh\n",
    "! curl -o observation_prediction.py http://josd.github.io/eye/transduction/observation_prediction.py\n",
    "! curl -o __init__.py http://josd.github.io/eye/transduction/__init__.py\n",
    "! curl -o sample.observation http://josd.github.io/eye/transduction/sample.observation\n",
    "! chmod +x observation_prediction.sh\n",
    "#% rm -fr ~/t2t_train/observation_prediction/transformer-transformer_small/\n",
    "#% rm -fr ~/t2t_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1215
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2844,
     "status": "ok",
     "timestamp": 1524660988496,
     "user": {
      "displayName": "Jos De Roo",
      "photoUrl": "//lh4.googleusercontent.com/-k8HF8cH0nRA/AAAAAAAAAAI/AAAAAAAAY58/KtQscbCb1JA/s50-c-k-no/photo.jpg",
      "userId": "112414952198343096006"
     },
     "user_tz": -120
    },
    "id": "RYpFkp0uykNE",
    "outputId": "e643b867-34c0-4464-a7e3-774967b9a06c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensor2tensor.data_generators\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m problem\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensor2tensor.data_generators\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m text_problems\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensor2tensor.utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m registry\r\n",
      "\r\n",
      "\u001b[30;01m@registry.register_problem\u001b[39;49;00m\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mObservationPrediction\u001b[39;49;00m(text_problems.Text2TextProblem):\r\n",
      "  \u001b[33m\"\"\"Transduction from observation to prediction.\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "  \u001b[30;01m@property\u001b[39;49;00m\r\n",
      "  \u001b[34mdef\u001b[39;49;00m \u001b[32mapprox_vocab_size\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[34m2\u001b[39;49;00m**\u001b[34m14\u001b[39;49;00m  \u001b[37m# ~16k\u001b[39;49;00m\r\n",
      "\r\n",
      "  \u001b[30;01m@property\u001b[39;49;00m\r\n",
      "  \u001b[34mdef\u001b[39;49;00m \u001b[32mis_generate_per_split\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "    \u001b[37m# generate_data will shard the data into TRAIN and EVAL for us.\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mFalse\u001b[39;49;00m\r\n",
      "\r\n",
      "  \u001b[30;01m@property\u001b[39;49;00m\r\n",
      "  \u001b[34mdef\u001b[39;49;00m \u001b[32mdataset_splits\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "    \u001b[33m\"\"\"Splits of data to produce and number of output shards for each.\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# 50% evaluation data\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m [{\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msplit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: problem.DatasetSplit.TRAIN,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mshards\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m5\u001b[39;49;00m,\r\n",
      "    }, {\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msplit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: problem.DatasetSplit.EVAL,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mshards\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m5\u001b[39;49;00m,\r\n",
      "    }]\r\n",
      "\r\n",
      "  \u001b[34mdef\u001b[39;49;00m \u001b[32mgenerate_samples\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, data_dir, tmp_dir, dataset_split):\r\n",
      "    \u001b[34mdel\u001b[39;49;00m data_dir\r\n",
      "    \u001b[34mdel\u001b[39;49;00m tmp_dir\r\n",
      "    \u001b[34mdel\u001b[39;49;00m dataset_split\r\n",
      "\r\n",
      "    \u001b[34mfor\u001b[39;49;00m n \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m10000\u001b[39;49;00m):\r\n",
      "      \u001b[37m# wind turbine size factor\u001b[39;49;00m\r\n",
      "      size_factor = random.randint(\u001b[34m1\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\r\n",
      "      \u001b[37m# wind speed\u001b[39;49;00m\r\n",
      "      wind_speed = \u001b[36mmax\u001b[39;49;00m(\u001b[34m0\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(random.gauss(\u001b[34m25\u001b[39;49;00m, \u001b[34m15\u001b[39;49;00m)))\r\n",
      "      \u001b[37m# wind turbine power\u001b[39;49;00m\r\n",
      "      turbine_power = \u001b[36mint\u001b[39;49;00m(\u001b[34m0.01\u001b[39;49;00m*size_factor*wind_speed**\u001b[34m3\u001b[39;49;00m)\r\n",
      "      \u001b[34myield\u001b[39;49;00m {\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_TURBINE with size factor \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(size_factor) + \u001b[33m\"\u001b[39;49;00m\u001b[33m and subjected to windspeed \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(wind_speed) + \u001b[33m\"\u001b[39;49;00m\u001b[33m km/h\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mtargets\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_TURBINE producing \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(turbine_power) + \u001b[33m\"\u001b[39;49;00m\u001b[33m kW\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      }\r\n",
      "\r\n",
      "      \u001b[37m# weight\u001b[39;49;00m\r\n",
      "      weight = \u001b[36mmax\u001b[39;49;00m(\u001b[34m35\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(random.gauss(\u001b[34m62\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m)))\r\n",
      "      \u001b[37m# height\u001b[39;49;00m\r\n",
      "      height = \u001b[36mmax\u001b[39;49;00m(\u001b[34m110\u001b[39;49;00m, \u001b[36mint\u001b[39;49;00m(random.gauss(\u001b[34m170\u001b[39;49;00m, \u001b[34m15\u001b[39;49;00m)))\r\n",
      "      \u001b[37m# body mass index\u001b[39;49;00m\r\n",
      "      bmi = \u001b[36mint\u001b[39;49;00m(weight/(height*\u001b[34m0.01\u001b[39;49;00m)**\u001b[34m2\u001b[39;49;00m)\r\n",
      "      \u001b[34mif\u001b[39;49;00m bmi < \u001b[34m18\u001b[39;49;00m:\r\n",
      "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mU\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m18\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m25\u001b[39;49;00m:\r\n",
      "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m25\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m30\u001b[39;49;00m:\r\n",
      "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m30\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m35\u001b[39;49;00m:\r\n",
      "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m35\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m bmi < \u001b[34m40\u001b[39;49;00m:\r\n",
      "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      \u001b[34melif\u001b[39;49;00m bmi >= \u001b[34m40\u001b[39;49;00m:\r\n",
      "        bmi_class = \u001b[33m\"\u001b[39;49;00m\u001b[33mO3\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      \u001b[34myield\u001b[39;49;00m {\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_PERSON with weight \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(weight) + \u001b[33m\"\u001b[39;49;00m\u001b[33m kg and height \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mrepr\u001b[39;49;00m(height) + \u001b[33m\"\u001b[39;49;00m\u001b[33m cm\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mtargets\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mA_PERSON has BMI class \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + bmi_class\r\n",
      "      }\r\n"
     ]
    }
   ],
   "source": [
    "# See the observation_prediction problem\n",
    "\n",
    "! pygmentize -g observation_prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2144,
     "status": "ok",
     "timestamp": 1524660990686,
     "user": {
      "displayName": "Jos De Roo",
      "photoUrl": "//lh4.googleusercontent.com/-k8HF8cH0nRA/AAAAAAAAAAI/AAAAAAAAY58/KtQscbCb1JA/s50-c-k-no/photo.jpg",
      "userId": "112414952198343096006"
     },
     "user_tz": -120
    },
    "id": "5F7TRqbByL1o",
    "outputId": "98b5e9b0-ee3f-478b-c0fc-3d4e11ba3e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/bin/bash\u001b[39;49;00m\r\n",
      "\u001b[31mPROBLEM\u001b[39;49;00m=observation_prediction\r\n",
      "\u001b[31mMODEL\u001b[39;49;00m=transformer\r\n",
      "\u001b[31mHPARAMS\u001b[39;49;00m=transformer_small\r\n",
      "\r\n",
      "\u001b[31mUSER_DIR\u001b[39;49;00m=\u001b[31m$PWD\u001b[39;49;00m\r\n",
      "\u001b[31mDATA_DIR\u001b[39;49;00m=\u001b[31m$HOME\u001b[39;49;00m/t2t_data\r\n",
      "\u001b[31mTMP_DIR\u001b[39;49;00m=/tmp/t2t_datagen\r\n",
      "\u001b[31mTRAIN_DIR\u001b[39;49;00m=\u001b[31m$HOME\u001b[39;49;00m/t2t_train/\u001b[31m$PROBLEM\u001b[39;49;00m/\u001b[31m$MODEL\u001b[39;49;00m-\u001b[31m$HPARAMS\u001b[39;49;00m\r\n",
      "\r\n",
      "mkdir -p \u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[31m$TMP_DIR\u001b[39;49;00m \u001b[31m$TRAIN_DIR\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Generate data\u001b[39;49;00m\r\n",
      "t2t-datagen \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --data_dir=\u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --problem=\u001b[31m$PROBLEM\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --t2t_usr_dir=\u001b[31m$USER_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --tmp_dir=\u001b[31m$TMP_DIR\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Train\u001b[39;49;00m\r\n",
      "t2t-trainer \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --data_dir=\u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --eval_steps=\u001b[34m3\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --hparams_set=\u001b[31m$HPARAMS\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --local_eval_frequency=\u001b[34m100\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --model=\u001b[31m$MODEL\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --output_dir=\u001b[31m$TRAIN_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --problem=\u001b[31m$PROBLEM\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --t2t_usr_dir=\u001b[31m$USER_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --train_steps=\u001b[34m2000\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --worker_gpu_memory_fraction=\u001b[34m0\u001b[39;49;00m.75\r\n",
      "\r\n",
      "\u001b[37m# Decode\u001b[39;49;00m\r\n",
      "t2t-decoder \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --data_dir=\u001b[31m$DATA_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --decode_from_file=sample.observation \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --decode_hparams=\u001b[33m\"beam_size=3,alpha=0.6,return_beams=True,write_beam_scores=True\"\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --decode_to_file=sample.prediction \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --hparams_set=\u001b[31m$HPARAMS\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --model=\u001b[31m$MODEL\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --output_dir=\u001b[31m$TRAIN_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --problem=\u001b[31m$PROBLEM\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --t2t_usr_dir=\u001b[31m$USER_DIR\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "  --worker_gpu_memory_fraction=\u001b[34m0\u001b[39;49;00m.75\r\n"
     ]
    }
   ],
   "source": [
    "# See the observation_prediction script\n",
    "\n",
    "! pygmentize -g observation_prediction.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 44791
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 964072,
     "status": "ok",
     "timestamp": 1524661954830,
     "user": {
      "displayName": "Jos De Roo",
      "photoUrl": "//lh4.googleusercontent.com/-k8HF8cH0nRA/AAAAAAAAAAI/AAAAAAAAY58/KtQscbCb1JA/s50-c-k-no/photo.jpg",
      "userId": "112414952198343096006"
     },
     "user_tz": -120
    },
    "id": "XqaxB8hqgoi6",
    "outputId": "93845a79-9c81-4baa-ccbe-ea228ca7672c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Importing user module Downloads from path /home/jdroo\n",
      "[2018-04-25 15:41:02,367] Importing user module Downloads from path /home/jdroo\n",
      "INFO:tensorflow:Generating problems:\n",
      "    observation:\n",
      "      * observation_prediction\n",
      "[2018-04-25 15:41:02,370] Generating problems:\n",
      "    observation:\n",
      "      * observation_prediction\n",
      "INFO:tensorflow:Generating data for observation_prediction.\n",
      "[2018-04-25 15:41:02,370] Generating data for observation_prediction.\n",
      "INFO:tensorflow:Found vocab file: /home/jdroo/t2t_data/vocab.observation_prediction.16384.subwords\n",
      "[2018-04-25 15:41:02,370] Found vocab file: /home/jdroo/t2t_data/vocab.observation_prediction.16384.subwords\n",
      "INFO:tensorflow:Skipping generator because outputs files exist\n",
      "[2018-04-25 15:41:02,378] Skipping generator because outputs files exist\n",
      "INFO:tensorflow:Skipping shuffle because output files exist\n",
      "[2018-04-25 15:41:02,381] Skipping shuffle because output files exist\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Importing user module Downloads from path /home/jdroo\n",
      "[2018-04-25 15:41:10,172] Importing user module Downloads from path /home/jdroo\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "[2018-04-25 15:41:10,235] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "[2018-04-25 15:41:10,236] schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "[2018-04-25 15:41:10,236] worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "[2018-04-25 15:41:10,236] sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "[2018-04-25 15:41:10,237] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "[2018-04-25 15:41:10,237] datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "[2018-04-25 15:41:10,237] caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "[2018-04-25 15:41:10,238] ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/jdroo/t2t_train/observation_prediction/transformer-transformer_small', '_keep_checkpoint_max': 20, '_tf_random_seed': 1234, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.75\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "  }\n",
      "}\n",
      ", '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_is_chief': True, '_num_worker_replicas': 0, '_environment': 'local', '_save_checkpoints_steps': 100, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb81135c18>, 'use_tpu': False, '_master': '', '_task_type': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fcb9b9ca4e0>, '_save_checkpoints_secs': None, '_task_id': 0, '_num_ps_replicas': 0, '_log_step_count_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_keep_checkpoint_every_n_hours': 10000}\n",
      "[2018-04-25 15:41:10,248] Using config: {'_model_dir': '/home/jdroo/t2t_train/observation_prediction/transformer-transformer_small', '_keep_checkpoint_max': 20, '_tf_random_seed': 1234, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.75\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "  }\n",
      "}\n",
      ", '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_is_chief': True, '_num_worker_replicas': 0, '_environment': 'local', '_save_checkpoints_steps': 100, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb81135c18>, 'use_tpu': False, '_master': '', '_task_type': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fcb9b9ca4e0>, '_save_checkpoints_secs': None, '_task_id': 0, '_num_ps_replicas': 0, '_log_step_count_steps': 100, 't2t_device_info': {'num_async_replicas': 1}, '_keep_checkpoint_every_n_hours': 10000}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fcb8111ad90>) includes params argument, but params are not passed to Estimator.\n",
      "[2018-04-25 15:41:10,248] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7fcb8111ad90>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "[2018-04-25 15:41:10,249] ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:334: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
      "[2018-04-25 15:41:10,250] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:334: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
      "WARNING:tensorflow:Experiment.continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
      "[2018-04-25 15:41:10,251] Experiment.continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Training model for 100 steps\n",
      "[2018-04-25 15:41:10,251] Training model for 100 steps\n",
      "INFO:tensorflow:Reading data files from /home/jdroo/t2t_data/observation_prediction-train*\n",
      "[2018-04-25 15:41:10,268] Reading data files from /home/jdroo/t2t_data/observation_prediction-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 5\n",
      "[2018-04-25 15:41:10,269] partition: 0 num_data_files: 5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2018-04-25 15:41:10,429] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "[2018-04-25 15:41:13,452] Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "[2018-04-25 15:41:13,453] Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_754_256.bottom\n",
      "[2018-04-25 15:41:13,493] Transforming feature 'inputs' with symbol_modality_754_256.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
      "[2018-04-25 15:41:13,680] Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "[2018-04-25 15:41:13,687] Building model body\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "[2018-04-25 15:41:13,770] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_754_256.top\n",
      "[2018-04-25 15:41:15,765] Transforming body output with symbol_modality_754_256.top\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1781: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "[2018-04-25 15:41:15,821] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:1781: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Base learning rate: 0.200000\n",
      "[2018-04-25 15:41:15,855] Base learning rate: 0.200000\n",
      "INFO:tensorflow:Trainable Variables Total size: 3882496\n",
      "[2018-04-25 15:41:15,867] Trainable Variables Total size: 3882496\n",
      "INFO:tensorflow:Using optimizer Adam\n",
      "[2018-04-25 15:41:15,867] Using optimizer Adam\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2018-04-25 15:41:19,365] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "[2018-04-25 15:41:19,366] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "[2018-04-25 15:41:20,937] Graph was finalized.\n",
      "2018-04-25 15:41:20.938217: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-04-25 15:41:21.051911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-04-25 15:41:21.052377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \n",
      "name: GeForce 840M major: 5 minor: 0 memoryClockRate(GHz): 1.124\n",
      "pciBusID: 0000:03:00.0\n",
      "totalMemory: 1.96GiB freeMemory: 1.78GiB\n",
      "2018-04-25 15:41:21.052409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\n",
      "2018-04-25 15:41:21.601897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-04-25 15:41:21.601940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \n",
      "2018-04-25 15:41:21.601947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \n",
      "2018-04-25 15:41:21.602124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1502 MB memory) -> physical GPU (device: 0, name: GeForce 840M, pci bus id: 0000:03:00.0, compute capability: 5.0)\n",
      "INFO:tensorflow:Restoring parameters from /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2800\n",
      "[2018-04-25 15:41:21,621] Restoring parameters from /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "[2018-04-25 15:41:22,432] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[2018-04-25 15:41:22,492] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2801 into /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
      "[2018-04-25 15:41:30,207] Saving checkpoints for 2801 into /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.015069826, step = 2800\n",
      "[2018-04-25 15:41:31,029] loss = 0.015069826, step = 2800\n",
      "INFO:tensorflow:Saving checkpoints for 2900 into /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
      "[2018-04-25 15:42:24,602] Saving checkpoints for 2900 into /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.012182581.\n",
      "[2018-04-25 15:42:25,460] Loss for final step: 0.012182581.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "[2018-04-25 15:42:25,462] Evaluating model now.\n",
      "INFO:tensorflow:Reading data files from /home/jdroo/t2t_data/observation_prediction-dev*\n",
      "[2018-04-25 15:42:25,468] Reading data files from /home/jdroo/t2t_data/observation_prediction-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 5\n",
      "[2018-04-25 15:42:25,469] partition: 0 num_data_files: 5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2018-04-25 15:42:25,594] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "[2018-04-25 15:42:28,515] Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "[2018-04-25 15:42:28,516] Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "[2018-04-25 15:42:28,516] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "[2018-04-25 15:42:28,516] Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "[2018-04-25 15:42:28,516] Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "[2018-04-25 15:42:28,516] Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "[2018-04-25 15:42:28,517] Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_754_256.bottom\n",
      "[2018-04-25 15:42:28,571] Transforming feature 'inputs' with symbol_modality_754_256.bottom\n",
      "INFO:tensorflow:Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
      "[2018-04-25 15:42:28,682] Transforming 'targets' with symbol_modality_754_256.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "[2018-04-25 15:42:28,691] Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_754_256.top\n",
      "[2018-04-25 15:42:31,020] Transforming body output with symbol_modality_754_256.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2018-04-25 15:42:31,647] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-25-13:42:31\n",
      "[2018-04-25 15:42:31,665] Starting evaluation at 2018-04-25-13:42:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "[2018-04-25 15:42:31,839] Graph was finalized.\n",
      "2018-04-25 15:42:31.839719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\n",
      "2018-04-25 15:42:31.839747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-04-25 15:42:31.839757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \n",
      "2018-04-25 15:42:31.839763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \n",
      "2018-04-25 15:42:31.839899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1502 MB memory) -> physical GPU (device: 0, name: GeForce 840M, pci bus id: 0000:03:00.0, compute capability: 5.0)\n",
      "INFO:tensorflow:Restoring parameters from /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2900\n",
      "[2018-04-25 15:42:31,840] Restoring parameters from /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "[2018-04-25 15:42:32,183] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[2018-04-25 15:42:32,230] Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/3]\n",
      "[2018-04-25 15:42:33,361] Evaluation [1/3]\n",
      "INFO:tensorflow:Evaluation [2/3]\n",
      "[2018-04-25 15:42:33,587] Evaluation [2/3]\n",
      "INFO:tensorflow:Evaluation [3/3]\n",
      "[2018-04-25 15:42:33,787] Evaluation [3/3]\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-25-13:42:33\n",
      "[2018-04-25 15:42:33,890] Finished evaluation at 2018-04-25-13:42:33\n",
      "INFO:tensorflow:Saving dict for global step 2900: global_step = 2900, loss = 0.03559239, metrics-observation_prediction/accuracy = 0.9957976, metrics-observation_prediction/accuracy_per_sequence = 0.97414964, metrics-observation_prediction/accuracy_top5 = 0.9989037, metrics-observation_prediction/approx_bleu_score = 0.75451136, metrics-observation_prediction/neg_log_perplexity = -0.09939319, metrics-observation_prediction/rouge_2_fscore = 0.82804865, metrics-observation_prediction/rouge_L_fscore = 0.79896814\n",
      "[2018-04-25 15:42:33,891] Saving dict for global step 2900: global_step = 2900, loss = 0.03559239, metrics-observation_prediction/accuracy = 0.9957976, metrics-observation_prediction/accuracy_per_sequence = 0.97414964, metrics-observation_prediction/accuracy_top5 = 0.9989037, metrics-observation_prediction/approx_bleu_score = 0.75451136, metrics-observation_prediction/neg_log_perplexity = -0.09939319, metrics-observation_prediction/rouge_2_fscore = 0.82804865, metrics-observation_prediction/rouge_L_fscore = 0.79896814\n",
      "INFO:tensorflow:Stop training model as max steps reached\n",
      "[2018-04-25 15:42:34,522] Stop training model as max steps reached\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Importing user module Downloads from path /home/jdroo\n",
      "[2018-04-25 15:42:43,009] Importing user module Downloads from path /home/jdroo\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "[2018-04-25 15:42:43,091] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/trainer_lib.py:152: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "[2018-04-25 15:42:43,092] schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "[2018-04-25 15:42:43,092] worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "[2018-04-25 15:42:43,092] sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "[2018-04-25 15:42:43,092] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "[2018-04-25 15:42:43,092] datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "[2018-04-25 15:42:43,092] caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "[2018-04-25 15:42:43,093] ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_tf_random_seed': 1234, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f03e5e1f0f0>, 't2t_device_info': {'num_async_replicas': 1}, '_evaluation_master': '', '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.75\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "  }\n",
      "}\n",
      ", '_model_dir': '/home/jdroo/t2t_train/observation_prediction/transformer-transformer_small', '_save_summary_steps': 100, '_num_ps_replicas': 0, '_master': '', '_task_id': 0, '_save_checkpoints_steps': 1000, '_num_worker_replicas': 0, 'use_tpu': False, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f03eda30400>, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None}\n",
      "[2018-04-25 15:42:43,093] Using config: {'_log_step_count_steps': 100, '_tf_random_seed': 1234, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f03e5e1f0f0>, 't2t_device_info': {'num_async_replicas': 1}, '_evaluation_master': '', '_is_chief': True, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.75\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "  }\n",
      "}\n",
      ", '_model_dir': '/home/jdroo/t2t_train/observation_prediction/transformer-transformer_small', '_save_summary_steps': 100, '_num_ps_replicas': 0, '_master': '', '_task_id': 0, '_save_checkpoints_steps': 1000, '_num_worker_replicas': 0, 'use_tpu': False, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f03eda30400>, '_keep_checkpoint_every_n_hours': 10000, '_task_type': None, '_keep_checkpoint_max': 20, '_save_checkpoints_secs': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f03e2043e18>) includes params argument, but params are not passed to Estimator.\n",
      "[2018-04-25 15:42:43,093] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f03e2043e18>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:decode_hp.batch_size not specified; default=32\n",
      "[2018-04-25 15:42:43,093] decode_hp.batch_size not specified; default=32\n",
      "INFO:tensorflow:Performing decoding from a file.\n",
      "[2018-04-25 15:42:43,093] Performing decoding from a file.\n",
      "INFO:tensorflow:Getting sorted inputs\n",
      "[2018-04-25 15:42:43,093] Getting sorted inputs\n",
      "INFO:tensorflow: batch 1\n",
      "[2018-04-25 15:42:43,100]  batch 1\n",
      "INFO:tensorflow:Decoding batch 0\n",
      "[2018-04-25 15:42:43,100] Decoding batch 0\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "[2018-04-25 15:42:43,106] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2018-04-25 15:42:43,106] Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "[2018-04-25 15:42:46,200] Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "[2018-04-25 15:42:46,201] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "[2018-04-25 15:42:46,201] Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "[2018-04-25 15:42:46,201] Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "[2018-04-25 15:42:46,201] Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "[2018-04-25 15:42:46,201] Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 3\n",
      "[2018-04-25 15:42:46,201] Beam Decoding with beam size 3\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "[2018-04-25 15:42:46,525] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/layers/common_layers.py:553: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/beam_search.py:93: calling reduce_logsumexp (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "[2018-04-25 15:42:48,950] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/beam_search.py:93: calling reduce_logsumexp (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2018-04-25 15:42:49,039] Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "[2018-04-25 15:42:49,241] Graph was finalized.\n",
      "2018-04-25 15:42:49.241973: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-04-25 15:42:49.350076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-04-25 15:42:49.350534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: \n",
      "name: GeForce 840M major: 5 minor: 0 memoryClockRate(GHz): 1.124\n",
      "pciBusID: 0000:03:00.0\n",
      "totalMemory: 1.96GiB freeMemory: 1.77GiB\n",
      "2018-04-25 15:42:49.350554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\n",
      "2018-04-25 15:42:49.975254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-04-25 15:42:49.975297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \n",
      "2018-04-25 15:42:49.975309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \n",
      "2018-04-25 15:42:49.975485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1502 MB memory) -> physical GPU (device: 0, name: GeForce 840M, pci bus id: 0000:03:00.0, compute capability: 5.0)\n",
      "INFO:tensorflow:Restoring parameters from /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2900\n",
      "[2018-04-25 15:42:49,994] Restoring parameters from /home/jdroo/t2t_train/observation_prediction/transformer-transformer_small/model.ckpt-2900\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "[2018-04-25 15:42:50,349] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[2018-04-25 15:42:50,373] Done running local_init_op.\n",
      "INFO:tensorflow:BEAM 0:\n",
      "[2018-04-25 15:42:52,776] BEAM 0:\n",
      "INFO:tensorflow:Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
      "[2018-04-25 15:42:52,777] Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
      "INFO:tensorflow:Inference results OUTPUT: A_TURBINE producing 9533 kW\n",
      "[2018-04-25 15:42:52,777] Inference results OUTPUT: A_TURBINE producing 9533 kW\n",
      "INFO:tensorflow:BEAM 1:\n",
      "[2018-04-25 15:42:52,777] BEAM 1:\n",
      "INFO:tensorflow:Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
      "[2018-04-25 15:42:52,777] Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
      "INFO:tensorflow:Inference results OUTPUT: A_TURBINE producing 19533 kW\n",
      "[2018-04-25 15:42:52,777] Inference results OUTPUT: A_TURBINE producing 19533 kW\n",
      "INFO:tensorflow:BEAM 2:\n",
      "[2018-04-25 15:42:52,777] BEAM 2:\n",
      "INFO:tensorflow:Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
      "[2018-04-25 15:42:52,777] Inference results INPUT: A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\n",
      "INFO:tensorflow:Inference results OUTPUT: A_TURBINE producing 119533 kW\n",
      "[2018-04-25 15:42:52,778] Inference results OUTPUT: A_TURBINE producing 119533 kW\n",
      "INFO:tensorflow:BEAM 0:\n",
      "[2018-04-25 15:42:52,778] BEAM 0:\n",
      "INFO:tensorflow:Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
      "[2018-04-25 15:42:52,778] Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
      "INFO:tensorflow:Inference results OUTPUT: A_PERSON has BMI class N\n",
      "[2018-04-25 15:42:52,778] Inference results OUTPUT: A_PERSON has BMI class N\n",
      "INFO:tensorflow:BEAM 1:\n",
      "[2018-04-25 15:42:52,778] BEAM 1:\n",
      "INFO:tensorflow:Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
      "[2018-04-25 15:42:52,778] Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
      "INFO:tensorflow:Inference results OUTPUT: A_PERSON has BMI class U\n",
      "[2018-04-25 15:42:52,778] Inference results OUTPUT: A_PERSON has BMI class U\n",
      "INFO:tensorflow:BEAM 2:\n",
      "[2018-04-25 15:42:52,778] BEAM 2:\n",
      "INFO:tensorflow:Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
      "[2018-04-25 15:42:52,779] Inference results INPUT: A_PERSON with weight 74 kg and height 179 cm\n",
      "INFO:tensorflow:Inference results OUTPUT: A_PERSON has BMI class N PERSON has BMI class N\n",
      "[2018-04-25 15:42:52,779] Inference results OUTPUT: A_PERSON has BMI class N PERSON has BMI class N\n",
      "INFO:tensorflow:Writing decodes into sample.prediction\n",
      "[2018-04-25 15:42:52,783] Writing decodes into sample.prediction\n"
     ]
    }
   ],
   "source": [
    "# Run the observation_prediction script\n",
    "\n",
    "! ./observation_prediction.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3850,
     "status": "ok",
     "timestamp": 1524661958750,
     "user": {
      "displayName": "Jos De Roo",
      "photoUrl": "//lh4.googleusercontent.com/-k8HF8cH0nRA/AAAAAAAAAAI/AAAAAAAAY58/KtQscbCb1JA/s50-c-k-no/photo.jpg",
      "userId": "112414952198343096006"
     },
     "user_tz": -120
    },
    "id": "ENGaCZllgojm",
    "outputId": "a81319cd-1e68-4371-a80d-c1b6b3d1a0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_PERSON with weight 74 kg and height 179 cm\r\n",
      "A_TURBINE with size factor 4 and subjected to windspeed 62 km/h\r\n",
      "->-\n",
      "A_PERSON has BMI class N\t-0.34\tA_PERSON has BMI class O\t-4.27\tA_PERSON has BMI class U\t-4.95\n",
      "A_TURBINE producing 9533 kW\t-0.35\tA_TURBINE producing 16682 kW\t-4.03\tA_TURBINE producing 2383 kW\t-4.12\n"
     ]
    }
   ],
   "source": [
    "# See the transductions\n",
    "# For each target the top 3 is shown with their scores (log probability)\n",
    "\n",
    "! pygmentize -g sample.observation\n",
    "print(\"->-\")\n",
    "! pygmentize -g sample.prediction"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "observation_prediction.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
